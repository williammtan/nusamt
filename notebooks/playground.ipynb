{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8c28fc-299e-4781-8eb4-e81895355cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a directory where the train is the dev and the test is the devtest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0481ef74-862a-4932-baab-e7fbbc791983",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLORES_DIR = \"/workspace/nllb-flores/floresp-v2.0-rc.3\"\n",
    "OUTPUT_DIR = \"../data/flores-200/\"\n",
    "\n",
    "LANGUAGE_PAIRS = [(\"ban\", \"en\"), (\"en\", \"ban\"), (\"ban\", \"id\"), (\"id\", \"ban\")]\n",
    "LANGUAGE_PAIRS_NLLB_MAP = {\"ban\": \"ban_Latn\", \"en\": \"eng_Latn\", \"id\": \"ind_Latn\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "062f464d-443f-434f-98ab-b094623f3701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def readlines(filepath):\n",
    "    with open(filepath) as f:\n",
    "        return [l for l in f.read().split('\\n') if l != \"\"]\n",
    "\n",
    "for src, tgt in LANGUAGE_PAIRS:\n",
    "    os.makedirs(os.path.join(OUTPUT_DIR, f\"{src}{tgt}\"), exist_ok=True)\n",
    "    \n",
    "    src_dev = readlines(os.path.join(FLORES_DIR, \"dev\", f\"dev.{LANGUAGE_PAIRS_NLLB_MAP[src]}\"))\n",
    "    tgt_dev = readlines(os.path.join(FLORES_DIR, \"dev\", f\"dev.{LANGUAGE_PAIRS_NLLB_MAP[tgt]}\"))\n",
    "    src_devtest = readlines(os.path.join(FLORES_DIR, \"devtest\", f\"devtest.{LANGUAGE_PAIRS_NLLB_MAP[src]}\"))\n",
    "    tgt_devtest = readlines(os.path.join(FLORES_DIR, \"devtest\", f\"devtest.{LANGUAGE_PAIRS_NLLB_MAP[tgt]}\"))\n",
    "\n",
    "\n",
    "    # TRAIN: train.src-tgt.json\n",
    "    with open(os.path.join(OUTPUT_DIR, f\"{src}{tgt}\", f\"train.{src}-{tgt}.json\"), 'w') as f:\n",
    "        translation_dicts = []\n",
    "        for i in range(len(src_dev)):\n",
    "            translation_dicts.append({\"translation\": {\n",
    "                src: src_dev[i],\n",
    "                tgt: tgt_dev[i]\n",
    "            }})\n",
    "\n",
    "        json.dump(translation_dicts, f)\n",
    "\n",
    "\n",
    "    with open(os.path.join(OUTPUT_DIR, f\"{src}{tgt}\", f\"valid.{src}-{tgt}.json\"), 'w') as f:\n",
    "        json.dump([{\n",
    "            \"translation\": {\n",
    "                src: src_dev[-1],\n",
    "                tgt: tgt_dev[-1]\n",
    "            }\n",
    "        }], f)\n",
    "    \n",
    "\n",
    "    # TEST: test.src-tgt.json + test.src-tgt.src + test.src-tgt.tgt\n",
    "    with open(os.path.join(OUTPUT_DIR, f\"{src}{tgt}\", f\"test.{src}-{tgt}.{src}\"), 'w') as src_f, open(os.path.join(OUTPUT_DIR, f\"{src}{tgt}\", f\"test.{src}-{tgt}.{tgt}\"), 'w') as tgt_f:\n",
    "        for i in range(len(src_devtest)):\n",
    "            src_f.write(src_devtest[i] + '\\n')\n",
    "            tgt_f.write(tgt_devtest[i] + '\\n')\n",
    "            \n",
    "\n",
    "    with open(os.path.join(OUTPUT_DIR, f\"{src}{tgt}\", f\"test.{src}-{tgt}.json\"), 'w') as f:\n",
    "        translation_dicts = []\n",
    "        for i in range(len(src_devtest)):\n",
    "            translation_dicts.append({\"translation\": {\n",
    "                src: src_devtest[i],\n",
    "                tgt: src_devtest[i]\n",
    "            }})\n",
    "\n",
    "        json.dump(translation_dicts, f)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "290044e4-9dcb-42bb-aad2-b4c0a3243e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8fe7d56dd9a467fa0a54ffc6611df2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/48.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8baaede2465457ea1768c34fd3ef0e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/8.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b348d9c67e447d6b206053073b53a87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Replace \"bal-Arab\" with the name of any other language available in the dataset\n",
    "# dataset = load_dataset(\"cis-lmu/glotcc-v1\", name=\"ban-Latn\", split=\"train\")\n",
    "dataset = load_dataset(\"cis-lmu/Glot500\", name=\"ban_Latn\", split=\"train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6339632d-81a7-48b8-9a49-2dcf71545f60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Buah delima mungkin salah satu buah yang paling terkenal untuk meningkatkan dorongan seks.',\n",
       "  'dataset': 'Leipzig_web',\n",
       "  'script': 'Latn',\n",
       "  'lang_script': 'Bali,Latn'},\n",
       " {'text': 'Ring warsa 2014, akéh krama ring désa Batubulan (proyéksi BPS) kirang langkung 21.443 diri sané kakepah antuk 10.818 lanang miwah 10.625 istri, taler tingkat sex rasionyané kirang langkung 101,82.',\n",
       "  'dataset': 'Leipzig_wikipedia',\n",
       "  'script': 'Latn',\n",
       "  'lang_script': 'Bali,Latn'},\n",
       " {'text': 'Dalam pendidikan kritis, guru tidak dianggap sebagai pusat segalanya.',\n",
       "  'dataset': 'Leipzig_web',\n",
       "  'script': 'Latn',\n",
       "  'lang_script': 'Bali,Latn'},\n",
       " {'text': 'Kebebasan Kuno taler nénten sami polih ring krama sané akidik miwah homogen, sané dangan antuk kramané mapupul sinarengan ring génah sané pateh anggén mareraosan indik pikobet umum.',\n",
       "  'dataset': 'nllb_seed',\n",
       "  'script': 'Latn',\n",
       "  'lang_script': 'Bali,Latn'},\n",
       " {'text': 'Ring Bali, aksara punika nenten tasih pralambang suara /ɻ/, nanging /rə/, suara getar rongga-gigi mawit vokal madya.',\n",
       "  'dataset': 'Leipzig_wikipedia',\n",
       "  'script': 'Latn',\n",
       "  'lang_script': 'Bali,Latn'},\n",
       " {'text': '4. Untuk membangun eksistensi dan martabat sebuah profesi diperlukan mutu atau kualitas para anggota yang tergabung dalam profesi tersebut.',\n",
       "  'dataset': 'Leipzig_web',\n",
       "  'script': 'Latn',\n",
       "  'lang_script': 'Bali,Latn'},\n",
       " {'text': '4. waktu tinggal air limbah didalam tangki diperkirakan minimal 24 jam. 6. pipa air masuk kedalam tangki hendaknya selalu lebih tinggi kurang lebh 2.5 cm dari pipa air keluar.',\n",
       "  'dataset': 'Leipzig_web',\n",
       "  'script': 'Latn',\n",
       "  'lang_script': 'Bali,Latn'},\n",
       " {'text': 'Kita sama-sama pesakitan bu, cuma nasib saya lebih baik dari Ibu dimana saya lulus, Ibu belum.',\n",
       "  'dataset': 'Leipzig_web',\n",
       "  'script': 'Latn',\n",
       "  'lang_script': 'Bali,Latn'},\n",
       " {'text': 'Bagian Umum terdiri dari: 1. Subbagian Tata Laksana dan Kepegawaian; 2. Subbagian Keuangan dan Rumah Tangga; 3. Subbagian Pengolahan Data.',\n",
       "  'dataset': 'Leipzig_web',\n",
       "  'script': 'Latn',\n",
       "  'lang_script': 'Bali,Latn'},\n",
       " {'text': 'Puniki ngicénin ngengat gelap pamargi sané becikan mangda prasida setata maurip pacang nadosang pianak ipun marwarna gelap, miwah wantah limang dasa tiban sesukat ngengat gelap matangkap, sampun akéh ngengat ring industri Manchester marwarna gelap.',\n",
       "  'dataset': 'nllb_seed',\n",
       "  'script': 'Latn',\n",
       "  'lang_script': 'Bali,Latn'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dataset)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c75c57e3-c8a4-4680-bc1d-a794b9c3e018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b61e0c58-823e-49d8-986c-36fa828c5513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4a3b893-e050-4676-bc74-4f1c258dd6e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ban-id.ban.combined.gz',\n",
       " 'WikiMatrix_v1_xml_id-ban.xml.gz',\n",
       " 'NLLB_latest_xml_id-ban.xml.gz',\n",
       " 'NLLB_latest_xml_ban-id.xml.gz',\n",
       " 'ban-id.ban.preprocessed.gz',\n",
       " 'ban-id.ban.filtered.gz',\n",
       " 'WikiMatrix_v1_xml_ban-id.xml.gz',\n",
       " 'ban-id.ban.valid.gz',\n",
       " 'ban-id.ban.train.gz',\n",
       " 'ban-id.ban.test.gz',\n",
       " 'ban-id.ban.raw.gz',\n",
       " 'ban-id.ban.preprocessed-dup.gz',\n",
       " 'ban-id.ban.final.gz',\n",
       " 'ban-id.ban.temp.gz',\n",
       " 'ban-id.id.combined.gz',\n",
       " 'ban-id.id.filtered.gz',\n",
       " 'ban-id.id.final.gz',\n",
       " 'ban-id.id.raw.gz',\n",
       " 'ban-id.id.temp.gz',\n",
       " 'ban-id.id.preprocessed-dup.gz',\n",
       " 'ban-id.id.preprocessed.gz',\n",
       " 'ban-id.id.test.gz',\n",
       " 'ban-id.nllbsub.id.gz',\n",
       " 'ban-id.id.train.gz',\n",
       " 'ban-id.nllbsub.ban.gz',\n",
       " 'ban-id.wikimatrix.ban.gz',\n",
       " 'ban-id.id.valid.gz',\n",
       " 'ban-id.wikimedia.ban.gz',\n",
       " 'ban-id.wikimatrix.id.gz',\n",
       " 'ban-id.wikimedia.id.gz',\n",
       " 'id-ban.ban.final.gz',\n",
       " 'id-ban.ban.temp.gz',\n",
       " 'id-ban.ban.valid.gz',\n",
       " 'id-ban.ban.train.gz',\n",
       " 'id-ban.id.final.gz',\n",
       " 'id-ban.id.temp.gz',\n",
       " 'id-ban.id.test.gz',\n",
       " 'id-ban.id.train.gz',\n",
       " 'id-ban.id.valid.gz',\n",
       " 'wikimedia_latest_xml_id-ban.xml.gz',\n",
       " 'wikimedia_latest_xml_ban-id.xml.gz',\n",
       " 'id-ban.ban.test.gz']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir('../data/ban/opus/ban-id/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "888c705b-14de-424b-afc8-ee41ec8821ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "with gzip.open(\"../data/ban/opus/ban-id/ban-id.id.preprocessed-dup.gz\", \"rt\") as f:\n",
    "    st = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1883b12-3b7e-4727-a4cd-78630819f9a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2775"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(st.split('\\n')) // 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8568056d-0f4b-494f-9de1-5f11db347a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7950714"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2775*443 + 2746032) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa47ed41-5f0a-4e4c-b2fc-31e5e9db02e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2746032"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens_from_string(st, 'gpt-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8bd09e0d-fd1e-42b6-84c5-e49730ff60b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "$0.075 / 1M input tokens\n",
    "$0.300 / 1M output tokens\n",
    "\n",
    "# INPUT:\n",
    "# 8 MILLION\n",
    "\n",
    "# OUTPUT:\n",
    "# 6 MILLION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc76abe1-7484-4309-9509-466125fee8cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8* 0.075 + 6 * 0.300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "740c5ebc-9317-40bb-9798-9c69e0813d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "162aa9c537794cae980eb5e90c0b9799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3709d5a091be42ffadee19c24b2bfa17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/28.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "The repository for Muennighoff/xP3x contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/Muennighoff/xP3x.\n",
      "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
      "\n",
      "Do you wish to run the custom code? [y/N]  y\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6730649157d84363aaa7ef007d63d053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/21.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0d12aa5eda54380831e194e0a40e392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0/1218 [00:00<?, ?files/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a84f1dd4a65e499582fa37bef3bc943e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"Muennighoff/xP3x\", \"min_Latn\") # Use streaming to not download all at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ee0ce75-80e6-43cf-bde9-3302abfcc97a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18fd111d24b24576ad1c8c2fc6fb7260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.41k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8c3f81460b247608fc9fa7843bbadce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/8.93k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "The repository for tatoeba contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/tatoeba.\n",
      "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
      "\n",
      "Do you wish to run the custom code? [y/N]  y\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Couldn't find file at https://object.pouta.csc.fi/OPUS-Tatoeba/v2021-07-22/moses/min_Latn-eng_Latn.txt.zip",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtatoeba\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmin_Latn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meng_Latn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/load.py:2616\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[1;32m   2613\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m builder_instance\u001b[38;5;241m.\u001b[39mas_streaming_dataset(split\u001b[38;5;241m=\u001b[39msplit)\n\u001b[1;32m   2615\u001b[0m \u001b[38;5;66;03m# Download and prepare data\u001b[39;00m\n\u001b[0;32m-> 2616\u001b[0m \u001b[43mbuilder_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2619\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2620\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2621\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2622\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2624\u001b[0m \u001b[38;5;66;03m# Build dataset for splits\u001b[39;00m\n\u001b[1;32m   2625\u001b[0m keep_in_memory \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2626\u001b[0m     keep_in_memory \u001b[38;5;28;01mif\u001b[39;00m keep_in_memory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m is_small_dataset(builder_instance\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdataset_size)\n\u001b[1;32m   2627\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/builder.py:1029\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[0;34m(self, output_dir, download_config, download_mode, verification_mode, ignore_verifications, try_from_hf_gcs, dl_manager, base_path, use_auth_token, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[0m\n\u001b[1;32m   1027\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m num_proc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1028\u001b[0m         prepare_split_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_proc\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_proc\n\u001b[0;32m-> 1029\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprepare_split_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1033\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdownload_and_prepare_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;66;03m# Sync info\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdataset_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(split\u001b[38;5;241m.\u001b[39mnum_bytes \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39msplits\u001b[38;5;241m.\u001b[39mvalues())\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/builder.py:1791\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._download_and_prepare\u001b[0;34m(self, dl_manager, verification_mode, **prepare_splits_kwargs)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_download_and_prepare\u001b[39m(\u001b[38;5;28mself\u001b[39m, dl_manager, verification_mode, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mprepare_splits_kwargs):\n\u001b[0;32m-> 1791\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1792\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1794\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_duplicate_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverification_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mVerificationMode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBASIC_CHECKS\u001b[49m\n\u001b[1;32m   1795\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mVerificationMode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mALL_CHECKS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1796\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprepare_splits_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1797\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/builder.py:1102\u001b[0m, in \u001b[0;36mDatasetBuilder._download_and_prepare\u001b[0;34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m split_dict \u001b[38;5;241m=\u001b[39m SplitDict(dataset_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_name)\n\u001b[1;32m   1101\u001b[0m split_generators_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_split_generators_kwargs(prepare_split_kwargs)\n\u001b[0;32m-> 1102\u001b[0m split_generators \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_split_generators\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msplit_generators_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;66;03m# Checksums verification\u001b[39;00m\n\u001b[1;32m   1105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verification_mode \u001b[38;5;241m==\u001b[39m VerificationMode\u001b[38;5;241m.\u001b[39mALL_CHECKS \u001b[38;5;129;01mand\u001b[39;00m dl_manager\u001b[38;5;241m.\u001b[39mrecord_checksums:\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/datasets_modules/datasets/tatoeba/b3ea9c6bb2af47699c5fc0a155643f5a0da287c7095ea14824ee0a8afd74daf6/tatoeba.py:104\u001b[0m, in \u001b[0;36mTatoeba._split_generators\u001b[0;34m(self, dl_manager)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _BASE_URL\u001b[38;5;241m.\u001b[39mformat(date, lang1, lang2)\n\u001b[1;32m    103\u001b[0m download_url \u001b[38;5;241m=\u001b[39m _base_url(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlang1, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlang2, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdate)\n\u001b[0;32m--> 104\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[43mdl_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_and_extract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdownload_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    106\u001b[0m     datasets\u001b[38;5;241m.\u001b[39mSplitGenerator(\n\u001b[1;32m    107\u001b[0m         name\u001b[38;5;241m=\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mSplit\u001b[38;5;241m.\u001b[39mTRAIN,\n\u001b[1;32m    108\u001b[0m         gen_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatapath\u001b[39m\u001b[38;5;124m\"\u001b[39m: path},\n\u001b[1;32m    109\u001b[0m     )\n\u001b[1;32m    110\u001b[0m ]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/download/download_manager.py:434\u001b[0m, in \u001b[0;36mDownloadManager.download_and_extract\u001b[0;34m(self, url_or_urls)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownload_and_extract\u001b[39m(\u001b[38;5;28mself\u001b[39m, url_or_urls):\n\u001b[1;32m    419\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Download and extract given `url_or_urls`.\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \n\u001b[1;32m    421\u001b[0m \u001b[38;5;124;03m    Is roughly equivalent to:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;124;03m        extracted_path(s): `str`, extracted paths of given URL(s).\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 434\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl_or_urls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/download/download_manager.py:257\u001b[0m, in \u001b[0;36mDownloadManager.download\u001b[0;34m(self, url_or_urls)\u001b[0m\n\u001b[1;32m    255\u001b[0m start_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m stack_multiprocessing_download_progress_bars():\n\u001b[0;32m--> 257\u001b[0m     downloaded_path_or_paths \u001b[38;5;241m=\u001b[39m \u001b[43mmap_nested\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownload_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_or_urls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmap_tuple\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDownloading data files\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m duration \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m    267\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mduration\u001b[38;5;241m.\u001b[39mtotal_seconds()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m60\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m min\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/utils/py_utils.py:484\u001b[0m, in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, parallel_min_length, batched, batch_size, types, disable_tqdm, desc)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batched:\n\u001b[1;32m    483\u001b[0m     data_struct \u001b[38;5;241m=\u001b[39m [data_struct]\n\u001b[0;32m--> 484\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_struct\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batched:\n\u001b[1;32m    486\u001b[0m     mapped \u001b[38;5;241m=\u001b[39m mapped[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/download/download_manager.py:313\u001b[0m, in \u001b[0;36mDownloadManager._download_batched\u001b[0;34m(self, url_or_filenames, download_config)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m thread_map(\n\u001b[1;32m    301\u001b[0m         download_func,\n\u001b[1;32m    302\u001b[0m         url_or_filenames,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    310\u001b[0m         tqdm_class\u001b[38;5;241m=\u001b[39mtqdm,\n\u001b[1;32m    311\u001b[0m     )\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    314\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download_single(url_or_filename, download_config\u001b[38;5;241m=\u001b[39mdownload_config)\n\u001b[1;32m    315\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m url_or_filename \u001b[38;5;129;01min\u001b[39;00m url_or_filenames\n\u001b[1;32m    316\u001b[0m     ]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/download/download_manager.py:314\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m thread_map(\n\u001b[1;32m    301\u001b[0m         download_func,\n\u001b[1;32m    302\u001b[0m         url_or_filenames,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    310\u001b[0m         tqdm_class\u001b[38;5;241m=\u001b[39mtqdm,\n\u001b[1;32m    311\u001b[0m     )\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m--> 314\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl_or_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m url_or_filename \u001b[38;5;129;01min\u001b[39;00m url_or_filenames\n\u001b[1;32m    316\u001b[0m     ]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/download/download_manager.py:323\u001b[0m, in \u001b[0;36mDownloadManager._download_single\u001b[0;34m(self, url_or_filename, download_config)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_relative_path(url_or_filename):\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;66;03m# append the relative path to the base_path\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     url_or_filename \u001b[38;5;241m=\u001b[39m url_or_path_join(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_base_path, url_or_filename)\n\u001b[0;32m--> 323\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mcached_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl_or_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    324\u001b[0m out \u001b[38;5;241m=\u001b[39m tracked_str(out)\n\u001b[1;32m    325\u001b[0m out\u001b[38;5;241m.\u001b[39mset_origin(url_or_filename)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/utils/file_utils.py:201\u001b[0m, in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, download_config, **download_kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m     url_or_filename \u001b[38;5;241m=\u001b[39m strip_protocol(url_or_filename)\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_remote_url(url_or_filename):\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# URL, so get it from the cache (downloading if necessary)\u001b[39;00m\n\u001b[0;32m--> 201\u001b[0m     output_path \u001b[38;5;241m=\u001b[39m \u001b[43mget_from_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_or_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_etag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_etag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_url_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_url_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownload_desc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_desc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable_tqdm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable_tqdm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(url_or_filename):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# File, and it exists.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     output_path \u001b[38;5;241m=\u001b[39m url_or_filename\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/utils/file_utils.py:630\u001b[0m, in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, local_files_only, use_etag, max_retries, token, use_auth_token, ignore_url_params, storage_options, download_desc, disable_tqdm)\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m    626\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot find the requested files in the cached path at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcache_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and outgoing traffic has been\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    627\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m disabled. To enable file online look-ups, set \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_files_only\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to False.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    628\u001b[0m     )\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m404\u001b[39m:\n\u001b[0;32m--> 630\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find file at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    631\u001b[0m _raise_if_offline_mode_is_enabled(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTried to reach \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head_error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Couldn't find file at https://object.pouta.csc.fi/OPUS-Tatoeba/v2021-07-22/moses/min_Latn-eng_Latn.txt.zip"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"tatoeba\", lang1=\"min_Latn\", lang2=\"eng_Latn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "76fd5eb1-dd86-4a54-b573-7a219c48fe42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "The repository for SEACrowd/minangnlp_mt contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/SEACrowd/minangnlp_mt.\n",
      "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
      "\n",
      "Do you wish to run the custom code? [y/N]  y\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67dbcefd02384e65b724048a55ba7a2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f105ee530ea54f09969ace21563baa81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c549a770bb84d889b508b67c45a5a71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daab3acebcb74c34a4725f59d7ce38a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = load_dataset(\"SEACrowd/minangnlp_mt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9ad3cf58-ff19-45a4-aeab-2d63d39201bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'min']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([\"id\", \"min\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ee16ac63-79a1-4c56-8904-0848fc069a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '0',\n",
       " 'src': 'walaupun biaut , kwa katiko diwawancarai straits times pado 2000 , manyabuik bahasonyo anak @-@ anak lee acok bamain di halaman rumah pado malam hari samentaro ayah mereka bamain golf\\n',\n",
       " 'tgt': 'terlepas dari itu , menurut sebuah wawancara dengan straits times 2000 dengan kwa , anak @-@ anak lee sering bermain di halaman rumah pada malam hari sementara ayah mereka bermain golf\\n'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "45446d42-5528-4f5c-be3f-51bc8ed7feb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '0',\n",
       " 'src': 'walaupun biaut , kwa katiko diwawancarai straits times pado 2000 , manyabuik bahasonyo anak @-@ anak lee acok bamain di halaman rumah pado malam hari samentaro ayah mereka bamain golf\\n',\n",
       " 'tgt': 'terlepas dari itu , menurut sebuah wawancara dengan straits times 2000 dengan kwa , anak @-@ anak lee sering bermain di halaman rumah pada malam hari sementara ayah mereka bermain golf\\n'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b1c35aad-8917-4add-8c1c-782c94715c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('https://huggingface.co/datasets/Exqrch/IndonesianNMT/raw/main/id-min.tsv', sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "800caada-6ed2-4bdf-8785-a4b3714e5356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Indonesian</th>\n",
       "      <th>Minangkabau</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rumah saya di Jakarta sangat besar dan luas de...</td>\n",
       "      <td>Rumah saya di Padang sangat luas dan bagus den...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>.Saat aku sedang menulis essay di meja belajar...</td>\n",
       "      <td>.Saat nan ado bariso tulis essay di mangaibo a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.Keberhasilan dalam suatu proses pengembangan ...</td>\n",
       "      <td>.Kapayuang lai dalam pagembangan saro lakuak m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Di pagi hari yang cerah ini, aku bangun dengan...</td>\n",
       "      <td>Dalam sako pagi nan ceria, akhe sakaliyo talam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Saya ingin membeli sebuah rumah yang luas, nya...</td>\n",
       "      <td>Saya kamariangan mangaduakan rumah yang pandai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056</th>\n",
       "      <td>Banyak orang yang mencari kebahagiaan dalam be...</td>\n",
       "      <td>Banyak urang nan mancari ka bahagiaan dalam ru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5057</th>\n",
       "      <td>Pertumbuhan ekonomi Indonesia meningkat signif...</td>\n",
       "      <td>Pambagian ekonomi di Minangkabau punyo kambali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5058</th>\n",
       "      <td>Sore itu, saat dia sedang melintasi jalan yang...</td>\n",
       "      <td>Sati itam, samentari dia sabalun keluaro baran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5059</th>\n",
       "      <td>Saat cuaca begitu panas, saya suka minum es ke...</td>\n",
       "      <td>Saat udaro begitu pangih, saya sukai minum pin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5060</th>\n",
       "      <td>Selama ini, saya selalu berusaha untuk mendapa...</td>\n",
       "      <td>Jajaso ko, urang selalupi mancoba nan baratak ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5060 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Indonesian  \\\n",
       "0     Rumah saya di Jakarta sangat besar dan luas de...   \n",
       "1     .Saat aku sedang menulis essay di meja belajar...   \n",
       "2     .Keberhasilan dalam suatu proses pengembangan ...   \n",
       "3     Di pagi hari yang cerah ini, aku bangun dengan...   \n",
       "4     Saya ingin membeli sebuah rumah yang luas, nya...   \n",
       "...                                                 ...   \n",
       "5056  Banyak orang yang mencari kebahagiaan dalam be...   \n",
       "5057  Pertumbuhan ekonomi Indonesia meningkat signif...   \n",
       "5058  Sore itu, saat dia sedang melintasi jalan yang...   \n",
       "5059  Saat cuaca begitu panas, saya suka minum es ke...   \n",
       "5060  Selama ini, saya selalu berusaha untuk mendapa...   \n",
       "\n",
       "                                            Minangkabau  \n",
       "0     Rumah saya di Padang sangat luas dan bagus den...  \n",
       "1     .Saat nan ado bariso tulis essay di mangaibo a...  \n",
       "2     .Kapayuang lai dalam pagembangan saro lakuak m...  \n",
       "3     Dalam sako pagi nan ceria, akhe sakaliyo talam...  \n",
       "4     Saya kamariangan mangaduakan rumah yang pandai...  \n",
       "...                                                 ...  \n",
       "5056  Banyak urang nan mancari ka bahagiaan dalam ru...  \n",
       "5057  Pambagian ekonomi di Minangkabau punyo kambali...  \n",
       "5058  Sati itam, samentari dia sabalun keluaro baran...  \n",
       "5059  Saat udaro begitu pangih, saya sukai minum pin...  \n",
       "5060  Jajaso ko, urang selalupi mancoba nan baratak ...  \n",
       "\n",
       "[5060 rows x 2 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0621d63e-2da9-43fe-99ae-f79e5f8c7e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-08-08 06:07:14--  https://huggingface.co/datasets/Exqrch/IndonesianNMT/raw/main/id-min.tsv\n",
      "Resolving huggingface.co (huggingface.co)... 13.225.131.93, 13.225.131.94, 13.225.131.35, ...\n",
      "Connecting to huggingface.co (huggingface.co)|13.225.131.93|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2255892 (2.2M) [text/plain]\n",
      "Saving to: ‘id-min.tsv’\n",
      "\n",
      "id-min.tsv          100%[===================>]   2.15M  2.44MB/s    in 0.9s    \n",
      "\n",
      "2024-08-08 06:07:15 (2.44 MB/s) - ‘id-min.tsv’ saved [2255892/2255892]\n",
      "\n",
      "--2024-08-08 06:07:15--  http://id-min.tsv/\n",
      "Resolving id-min.tsv (id-min.tsv)... failed: Name or service not known.\n",
      "wget: unable to resolve host address ‘id-min.tsv’\n",
      "FINISHED --2024-08-08 06:07:15--\n",
      "Total wall clock time: 1.2s\n",
      "Downloaded: 1 files, 2.2M in 0.9s (2.44 MB/s)\n"
     ]
    }
   ],
   "source": [
    "!wget https://huggingface.co/datasets/Exqrch/IndonesianNMT/raw/main/id-min.tsv \"id-min.tsv\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
