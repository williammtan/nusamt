{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6759a802-2822-445b-a3f0-2008126d80ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import subprocess\n",
    "\n",
    "FLORES_DIR = \"../data/flores-200/\"\n",
    "\n",
    "def get_lang_directions(languages, base_languages, order_matters=True, skip_base_pairs=False):\n",
    "    \"\"\"Helper function to generate the language directions.\"\"\"\n",
    "\n",
    "    directions = []\n",
    "    \n",
    "    for base in base_languages:\n",
    "        if skip_base_pairs:\n",
    "            other_languages = [lang for lang in languages if lang not in base_languages]\n",
    "        else:\n",
    "            other_languages = [lang for lang in languages if lang != base]\n",
    "\n",
    "        for lang in other_languages:\n",
    "\n",
    "            if order_matters:\n",
    "                directions.append((base, lang))\n",
    "                directions.append((lang, base))\n",
    "            else:\n",
    "                pair = tuple(sorted([base, lang]))\n",
    "                if pair not in directions:\n",
    "                    directions.append(pair)\n",
    "    \n",
    "    return directions\n",
    "\n",
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "def translate(model, tokenizer, sentences, target_language):\n",
    "    translated_sentences = []\n",
    "    \n",
    "    for c in tqdm(chunks(sentences, BATCH_SIZE), total=int(len(sentences)/BATCH_SIZE)):\n",
    "        # print(c)\n",
    "        inputs = tokenizer(c, return_tensors=\"pt\", padding=True).to(\"cuda\")\n",
    "        # print(inputs)\n",
    "    \n",
    "        translated_tokens = model.generate(\n",
    "            inputs[\"input_ids\"], forced_bos_token_id=tokenizer.convert_tokens_to_ids(target_language), max_length=256\n",
    "        )\n",
    "        translated_sentences.extend(tokenizer.batch_decode(translated_tokens, skip_special_tokens=True))\n",
    "\n",
    "    return translated_sentences\n",
    "\n",
    "def load_flores(src, tgt):\n",
    "    \"\"\"Loads the flores devtest dataset from the flores-200 directory\"\"\"\n",
    "    with open(os.path.join(FLORES_DIR, f\"{src}{tgt}\", f\"test.{src}-{tgt}.json\")) as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def get_flores_tgt_file(src, tgt):\n",
    "    return os.path.join(FLORES_DIR, f\"{src}{tgt}\", f\"test.{src}-{tgt}.{tgt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87b7a376-9bd0-428e-bcb2-75fe1b4d2db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=16\n",
    "\n",
    "MODELS = [\"facebook/nllb-200-distilled-600M\", \"facebook/nllb-200-1.3B\", \"facebook/nllb-200-3.3B\"]\n",
    "OUTPUT_DIR = \"../data/benchmarks/\"\n",
    "METRICS = [\"bleu\", \"chrf\"]\n",
    "CHRF_plus = True\n",
    "SACREBLEU_TOKENIZER = \"flores200\"\n",
    "\n",
    "USE_CACHED = True\n",
    "\n",
    "LANGUAGE_PAIRS_NLLB_MAP = {\"ban\": \"ban_Latn\", \"min\": \"min_Latn\", \"en\": \"eng_Latn\", \"id\": \"ind_Latn\"}\n",
    "TGT_LANGUAGES = [\"ban\", \"min\"]\n",
    "BASE_LANGUAGES = [\"en\", \"id\"]\n",
    "METRIC_MAPPING = {\"BLEU\": \"bleu\", \"chrF2++\": \"chrf\"}\n",
    "DIRECTIONS = get_lang_directions(TGT_LANGUAGES, BASE_LANGUAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "733e2be4-5ec7-41a0-8153-29ae0af40f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1018310/3548010380.py:52: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  dfs[METRIC_MAPPING[m[\"name\"]]].loc[model_name][src+'-'+tgt] = float(m[\"score\"])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d719c91fb1004db79eb06104e0cf9372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/564 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81e45fb7b074495f83a7f729d6bd9662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/4.85M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d2ec3a387a34a88913fe3952c4023c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dcea30ae7034ad5b1e09e1f3d2f15ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/3.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "64it [02:23,  2.25s/it]                        \n",
      "64it [01:50,  1.73s/it]                        \n",
      "64it [02:04,  1.95s/it]                        \n",
      "64it [01:52,  1.76s/it]                        \n",
      "64it [02:28,  2.31s/it]                        \n",
      "64it [01:44,  1.63s/it]                        \n",
      "64it [02:13,  2.08s/it]                        \n",
      "64it [01:47,  1.68s/it]                        \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "679030b8779d46f4a3712140ce1d28d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "dfs = {\n",
    "    m: pd.DataFrame(columns=['-'.join(d) for d in DIRECTIONS])\n",
    "    for m in METRICS\n",
    "}\n",
    "\n",
    "for m in dfs.keys():\n",
    "    for model_name in MODELS:\n",
    "        dfs[m].loc[model_name] = \"\"\n",
    "\n",
    "for model_name in MODELS:\n",
    "    MODEL_RESULTS_DIR = os.path.join(OUTPUT_DIR, model_name.replace(\"facebook/\", \"\"))\n",
    "    \n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "    model.to(\"cuda\")\n",
    "\n",
    "    for src, tgt in DIRECTIONS:\n",
    "        DIRECTION_RESULTS_DIR = os.path.join(MODEL_RESULTS_DIR, f\"{src}{tgt}\")\n",
    "        os.makedirs(DIRECTION_RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "        sentence_output_path = os.path.join(DIRECTION_RESULTS_DIR, f\"test-{src}-{tgt}\")\n",
    "        bleu_output_path = sentence_output_path + \".metrics.json\"\n",
    "\n",
    "        if not (os.path.isfile(bleu_output_path) and USE_CACHED):\n",
    "            # run if there isn't a file\n",
    "        \n",
    "            translations = load_flores(src, tgt)\n",
    "            src_sentences = [t[\"translation\"][src] for t in translations]\n",
    "            \n",
    "            tokenizer = AutoTokenizer.from_pretrained(\n",
    "                model_name, src_lang=LANGUAGE_PAIRS_NLLB_MAP[src]\n",
    "            )\n",
    "    \n",
    "            translated_sentences = translate(model, tokenizer, src_sentences, LANGUAGE_PAIRS_NLLB_MAP[tgt])\n",
    "    \n",
    "            # Dump to test-{src}-{tgt}\n",
    "            \n",
    "            with open(sentence_output_path, \"w\") as f:\n",
    "                f.write('\\n'.join(translated_sentences))\n",
    "    \n",
    "            # calculate bleu score by running the command\n",
    "            command = f\"sacrebleu -tok {SACREBLEU_TOKENIZER} -w 2 {get_flores_tgt_file(src, tgt)} -m {' '.join(METRICS)}\"\n",
    "            if CHRF_plus:\n",
    "                command += ' --chrf-word-order 2'\n",
    "            command += f\" < {sentence_output_path} > {bleu_output_path}\"\n",
    "\n",
    "            process = subprocess.run(command, shell=True, check=True, text=True)\n",
    "\n",
    "        with open(bleu_output_path, 'r') as f:\n",
    "            metrics = json.load(f)\n",
    "\n",
    "        for m in metrics:\n",
    "            dfs[METRIC_MAPPING[m[\"name\"]]].loc[model_name][src+'-'+tgt] = float(m[\"score\"])\n",
    "    \n",
    "\n",
    "\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d5157a4-86c0-484a-a789-6cc2c1c40ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1018310/2727566634.py:28: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  dfs[METRIC_MAPPING[m[\"name\"]]].loc[\"nllb-moe-54b\"][src+'-'+tgt] = float(m[\"score\"])\n"
     ]
    }
   ],
   "source": [
    "# FOR NLLB-54 MOE model\n",
    "\n",
    "NLLB_PREDICTIONS_DIR = \"../../nllb-flores/flores_translations/\"\n",
    "\n",
    "for m in dfs.keys():\n",
    "    dfs[m].loc[\"nllb-moe-54b\"] = \"\"\n",
    "\n",
    "for src, tgt in DIRECTIONS:\n",
    "    DIRECTION_RESULTS_DIR = os.path.join(MODEL_RESULTS_DIR, f\"{src}{tgt}\")\n",
    "    os.makedirs(DIRECTION_RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "    src_path = os.path.join(NLLB_PREDICTIONS_DIR, f\"flores200-{LANGUAGE_PAIRS_NLLB_MAP[src]}-{LANGUAGE_PAIRS_NLLB_MAP[tgt]}-devtest.hyp\")\n",
    "    sentence_output_path = os.path.join(DIRECTION_RESULTS_DIR, f\"test-{src}-{tgt}\")\n",
    "    bleu_output_path = sentence_output_path + \".metrics.json\"\n",
    "\n",
    "    if not (os.path.isfile(bleu_output_path) and USE_CACHED):\n",
    "        command = f\"sacrebleu -tok {SACREBLEU_TOKENIZER} -w 2 {get_flores_tgt_file(src, tgt)} -m {' '.join(METRICS)}\"\n",
    "        if CHRF_plus:\n",
    "            command += ' --chrf-word-order 2'\n",
    "        command += f\" < {src_path} > {bleu_output_path}\"\n",
    "\n",
    "        process = subprocess.run(command, shell=True, check=True, text=True)\n",
    "\n",
    "    with open(bleu_output_path, 'r') as f:\n",
    "        metrics = json.load(f)\n",
    "\n",
    "    for m in metrics:\n",
    "        dfs[METRIC_MAPPING[m[\"name\"]]].loc[\"nllb-moe-54b\"][src+'-'+tgt] = float(m[\"score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9c2883c-9ebb-4b64-92b8-89b2231589a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m, df in dfs.items():\n",
    "    dfs[m].to_csv(os.path.join(OUTPUT_DIR, f\"nllb.{m}.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d5c4e94-7d9b-4f5d-8586-d5e77f9c56fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"ban-en\",\"en-ban\",\"ban-id\",\"id-ban\", \"min-en\",\"en-min\",\"min-id\",\"id-min\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "016434bf-8e49-48a2-a310-b2484fe58b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ban-en</th>\n",
       "      <th>en-ban</th>\n",
       "      <th>ban-id</th>\n",
       "      <th>id-ban</th>\n",
       "      <th>min-en</th>\n",
       "      <th>en-min</th>\n",
       "      <th>min-id</th>\n",
       "      <th>id-min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>facebook/nllb-200-distilled-600M</th>\n",
       "      <td>33.96</td>\n",
       "      <td>16.86</td>\n",
       "      <td>30.12</td>\n",
       "      <td>15.15</td>\n",
       "      <td>35.05</td>\n",
       "      <td>19.72</td>\n",
       "      <td>31.92</td>\n",
       "      <td>17.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facebook/nllb-200-1.3B</th>\n",
       "      <td>37.24</td>\n",
       "      <td>17.73</td>\n",
       "      <td>32.42</td>\n",
       "      <td>16.21</td>\n",
       "      <td>38.59</td>\n",
       "      <td>22.79</td>\n",
       "      <td>34.68</td>\n",
       "      <td>20.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facebook/nllb-200-3.3B</th>\n",
       "      <td>38.57</td>\n",
       "      <td>17.09</td>\n",
       "      <td>33.35</td>\n",
       "      <td>14.85</td>\n",
       "      <td>40.61</td>\n",
       "      <td>24.71</td>\n",
       "      <td>35.2</td>\n",
       "      <td>22.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nllb-moe-54b</th>\n",
       "      <td>38.57</td>\n",
       "      <td>17.09</td>\n",
       "      <td>33.35</td>\n",
       "      <td>14.85</td>\n",
       "      <td>40.61</td>\n",
       "      <td>24.71</td>\n",
       "      <td>35.2</td>\n",
       "      <td>22.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 ban-en en-ban ban-id id-ban min-en en-min  \\\n",
       "facebook/nllb-200-distilled-600M  33.96  16.86  30.12  15.15  35.05  19.72   \n",
       "facebook/nllb-200-1.3B            37.24  17.73  32.42  16.21  38.59  22.79   \n",
       "facebook/nllb-200-3.3B            38.57  17.09  33.35  14.85  40.61  24.71   \n",
       "nllb-moe-54b                      38.57  17.09  33.35  14.85  40.61  24.71   \n",
       "\n",
       "                                 min-id id-min  \n",
       "facebook/nllb-200-distilled-600M  31.92  17.72  \n",
       "facebook/nllb-200-1.3B            34.68  20.89  \n",
       "facebook/nllb-200-3.3B             35.2  22.44  \n",
       "nllb-moe-54b                       35.2  22.44  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['bleu'][columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16a01eb2-770a-41ad-9b8e-c5dc351e109c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ban-en</th>\n",
       "      <th>en-ban</th>\n",
       "      <th>ban-id</th>\n",
       "      <th>id-ban</th>\n",
       "      <th>min-en</th>\n",
       "      <th>en-min</th>\n",
       "      <th>min-id</th>\n",
       "      <th>id-min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>facebook/nllb-200-distilled-600M</th>\n",
       "      <td>54.4</td>\n",
       "      <td>42.7</td>\n",
       "      <td>53.83</td>\n",
       "      <td>40.71</td>\n",
       "      <td>55.41</td>\n",
       "      <td>46.18</td>\n",
       "      <td>56.06</td>\n",
       "      <td>44.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facebook/nllb-200-1.3B</th>\n",
       "      <td>57.2</td>\n",
       "      <td>43.21</td>\n",
       "      <td>55.48</td>\n",
       "      <td>41.5</td>\n",
       "      <td>58.16</td>\n",
       "      <td>47.96</td>\n",
       "      <td>57.94</td>\n",
       "      <td>46.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facebook/nllb-200-3.3B</th>\n",
       "      <td>58.01</td>\n",
       "      <td>42.24</td>\n",
       "      <td>56.34</td>\n",
       "      <td>39.75</td>\n",
       "      <td>59.84</td>\n",
       "      <td>49.27</td>\n",
       "      <td>58.32</td>\n",
       "      <td>47.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nllb-moe-54b</th>\n",
       "      <td>58.01</td>\n",
       "      <td>42.24</td>\n",
       "      <td>56.34</td>\n",
       "      <td>39.75</td>\n",
       "      <td>59.84</td>\n",
       "      <td>49.27</td>\n",
       "      <td>58.32</td>\n",
       "      <td>47.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 ban-en en-ban ban-id id-ban min-en en-min  \\\n",
       "facebook/nllb-200-distilled-600M   54.4   42.7  53.83  40.71  55.41  46.18   \n",
       "facebook/nllb-200-1.3B             57.2  43.21  55.48   41.5  58.16  47.96   \n",
       "facebook/nllb-200-3.3B            58.01  42.24  56.34  39.75  59.84  49.27   \n",
       "nllb-moe-54b                      58.01  42.24  56.34  39.75  59.84  49.27   \n",
       "\n",
       "                                 min-id id-min  \n",
       "facebook/nllb-200-distilled-600M  56.06  44.03  \n",
       "facebook/nllb-200-1.3B            57.94  46.39  \n",
       "facebook/nllb-200-3.3B            58.32  47.74  \n",
       "nllb-moe-54b                      58.32  47.74  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['chrf'][columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "386623b3-433b-4cfd-b6f2-184d0f4712e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "\n",
    "with gzip.open(\"../.cache/preprocess/seed/ban-en.ban.gz\", \"rt\") as src, gzip.open(\"../.cache/preprocess/seed/ban-en.en.gz\", \"rt\") as tgt:\n",
    "    src_sentences = src.read().split('\\n')\n",
    "    tgt_sentences = tgt.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f397295d-722e-4b13-bed3-223c4fbf8be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "388it [15:55,  2.46s/it]                         \n"
     ]
    }
   ],
   "source": [
    "tgt_translated = translate(tgt_sentences, \"ind_Latn\") # translate the english to balinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d291b31d-54b7-4667-89de-44e209776538",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(\"../.cache/preprocess/seed/ban-id.ban.gz\", \"wt\") as src, gzip.open(\"../.cache/preprocess/seed/ban-id.id.gz\", \"wt\") as tgt:\n",
    "    for i in range(len(src_sentences)):\n",
    "        src.write(src_sentences[i] + '\\n')\n",
    "        tgt.write(tgt_translated[i] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b6c12df-2a95-472f-bd5f-3c0d48597dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lilian Diana Gish (14 Oktober 1893 - 27 Februari 1993) inggih punika aktris, sutradara, miwah penulis skenario Amerika.',\n",
       " 'Gish inggih punika bintang film sane kasub ring warsa 1912 kanti 1920-an, sane manut khusus kaasosiasinin antuk film-film sutradara D. W. Griffith.',\n",
       " 'Ia taler ngalaksanayang pagaen televise sane sedeng gede saking awal 1950-an kanti 1980-an, lan muputang gae mplalian nglawan Bette Davis ring film 1987 The Whales of August.',\n",
       " 'Makudang-kudang generasi kapertama Gish inggih punika menteri Dunkard.',\n",
       " 'Biang ipunne ngamukakang Majestic Candy Kitchen, lan luh-luh punika ngawantu ngadol popcorn lan permen ka pelanggan Majestic Theater sue, sane matongos ring sampingne.',\n",
       " 'Lilian sane mayusa pitulas warsa ngalaksanayang pamargin ka Shawnee, Oklahoma, ring dije nyamane muani James, Alfred Grant Grish lan kurenanne, Maude, manongos.',\n",
       " 'Ajine padem ring Norman, Oklahoma, ring warsa 1912, nanging ia sampun mawali ka Ohio makudang-kudang sasih sadurungne.',\n",
       " 'Dugas Lilian lan Dorothy sedeng dewasa, ipun magabung antuk teater, sesai mamesu manut sakadi mapalas ring produksi sane mabinayan.',\n",
       " 'Gish sai tampil ring duur panggung, lan saking warsa 1913, sasue ngajalanin A Good Little Devil, ia pingsan mawinan anemia.',\n",
       " 'Perawakanne ring kondisi dingin puniki mawinan ngerusakang saraf ring makudang-kudang jriji.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ebab3d5-e095-4cac-ac19-e4e9504e6eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lillian Diana Gish (October 14, 1893 â€“ February 27, 1993) was an American actress, director and screenwriter.',\n",
       " 'Gish was a prominent film star from 1912 into the 1920s, being particularly associated with the films of director D. W. Griffith.',\n",
       " 'She also did considerable television work from the early 1950s into the 1980s, and closed her career playing opposite Bette Davis in the 1987 film The Whales of August.',\n",
       " 'The first several generations of Gishes were Dunkard ministers.',\n",
       " 'Their mother opened the Majestic Candy Kitchen, and the girls helped sell popcorn and candy to patrons of the old Majestic Theater, located next door.',\n",
       " \"The seventeen-year-old Lillian traveled to Shawnee, Oklahoma, where James's brother Alfred Grant Gish and his wife, Maude, lived.\",\n",
       " 'Her father died in Norman, Oklahoma, in 1912, but she had returned to Ohio a few months before this.',\n",
       " 'When Lillian and Dorothy were old enough they joined the theatre, often traveling separately in different productions.',\n",
       " 'Gish continued to perform on the stage, and in 1913, during a run of A Good Little Devil, she collapsed from anemia.',\n",
       " 'Her performance in these frigid conditions gave her lasting nerve damage in several fingers.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1f1eb7cd-09ee-4f62-8c3a-9a128adb998f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"flores-eval/enban/test.en-ban.en\", \"r\") as f:\n",
    "    src_sentences = [s for s in f.read().split('\\n') if s != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e8266a06-c459-4d2c-bb3c-cd3e3153f1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"openai/enban/nllb200-response.ban\", \"w\") as f:\n",
    "    f.write('\\n'.join(tgt_sentences))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
